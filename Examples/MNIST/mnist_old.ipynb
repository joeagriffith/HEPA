{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2.functional as F_v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from Methods.HEPA.model import HEPA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimiser(model, optimiser, lr, wd, exclude_bias=True, exclude_bn=True, momentum=0.9, betas=(0.9, 0.999)):\n",
    "    non_decay_parameters = []\n",
    "    decay_parameters = []   \n",
    "    for n, p in model.named_parameters():\n",
    "        if exclude_bias and 'bias' in n:\n",
    "            non_decay_parameters.append(p)\n",
    "        elif exclude_bn and 'bn' in n:\n",
    "            non_decay_parameters.append(p)\n",
    "        else:\n",
    "            decay_parameters.append(p)\n",
    "    non_decay_parameters = [{'params': non_decay_parameters, 'weight_decay': 0.0}]\n",
    "    decay_parameters = [{'params': decay_parameters}]\n",
    "\n",
    "    assert optimiser in ['AdamW', 'SGD'], 'optimiser must be one of [\"AdamW\", \"SGD\"]'\n",
    "    if optimiser == 'AdamW':\n",
    "        if momentum != 0.9:\n",
    "            print('Warning: AdamW does not accept momentum parameter. Ignoring it. Please specify betas instead.')\n",
    "        optimiser = torch.optim.AdamW(decay_parameters + non_decay_parameters, lr=lr, weight_decay=wd, betas=betas)\n",
    "    elif optimiser == 'SGD':\n",
    "        if betas != (0.9, 0.999):\n",
    "            print('Warning: SGD does not accept betas parameter. Ignoring it. Please specify momentum instead.')\n",
    "        optimiser = torch.optim.SGD(decay_parameters + non_decay_parameters, lr=lr, weight_decay=wd, momentum=momentum)\n",
    "    \n",
    "    return optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='../Datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root='../Datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Pad(2),\n",
    "    # transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Pad(2),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform()\n",
    "])\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomCrop(20),\n",
    "    transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.RandomAffine(degrees=180, translate=(0.28, 0.28), scale=(0.75, 1.25), shear=25),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.75, 1.25), shear=25),\n",
    "    # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, train_transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, val_transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, val_transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: tensor(1., device='cuda:0')\n",
      "Min value: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Show example images\n",
    "# fig, axes = plt.subplots(1, 10, figsize=(15,5))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     img, label = train_set[i]\n",
    "#     angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "#     translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "#     translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "#     scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "#     shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "#     img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "#     ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "#     ax.set_title(f\"Label: {label}\")\n",
    "#     ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# show before and after on each row\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15,5))\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    img, label = train_set[i+20]\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    img, label = train_set[i+20]\n",
    "    angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "    shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "    img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# print max and min values\n",
    "print('Max value:', train_set.transformed_images.max())\n",
    "print('Min value:', train_set.transformed_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset transform: Compose(\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 - Train Loss: 0.0688 - LR: 0.0003 - WD: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 - Train Loss: 0.0456 - LR: 0.0003 - WD: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 - Train Loss: 0.0384 - LR: 0.0003 - WD: 0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 - Train Loss: 0.0331 - LR: 0.0003 - WD: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - Train Loss: 0.0319 - LR: 0.0003 - WD: 0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Methods.HEPA.train_basic import train as train_hepa_basic\n",
    "from Models import iGPA\n",
    "from Utils.utils import get_optimiser\n",
    "from Utils.train_min import train\n",
    "\n",
    "model = iGPA(1, 5).to(device)\n",
    "# optimiser = get_optimiser(\n",
    "#     model, \n",
    "#     'AdamW', \n",
    "#     lr=3e-4, \n",
    "#     wd=0.004, \n",
    "#     exclude_bias=True,\n",
    "#     exclude_bn=True,\n",
    "# )\n",
    "cfg = {\n",
    "    'optimiser': 'AdamW',\n",
    "    'exclude_bias': True,\n",
    "    'exclude_bn': True,\n",
    "    'betas': (0.9, 0.999),\n",
    "    'momentum': 0.9,\n",
    "}\n",
    "optimiser = get_optimiser(model, cfg)\n",
    "train_set.transform = transforms.Compose([\n",
    "])\n",
    "train_losses = train_hepa_basic(\n",
    "    model,\n",
    "    optimiser,\n",
    "    train_set,\n",
    "    val_set,\n",
    "    num_epochs=250,\n",
    "    batch_size=256,\n",
    "    stop_at=0,\n",
    "    train_aug_scaler='none',\n",
    "    val_aug_scaler='none',\n",
    "    loss_fn='mse',\n",
    "    learn_on_ss=False,\n",
    "    writer=None,\n",
    "    save_dir=None,\n",
    "    save_every=5,\n",
    ")\n",
    "# train_cfg = {\n",
    "#     'device': 'cuda',\n",
    "#     'ddp_rank': 0,\n",
    "#     'warmup': 10,\n",
    "#     'flat': 0,\n",
    "#     'num_epochs': 250,\n",
    "#     'batch_size': 256,\n",
    "#     'start_lr': 3e-4,\n",
    "#     'end_lr': 1e-6,\n",
    "#     'start_wd': 0.04,\n",
    "#     'end_wd': 0.4,\n",
    "#     'decay_lr': True,\n",
    "#     'master_process': True,\n",
    "#     'local': True,\n",
    "#     'dataset': 'mnist',\n",
    "# }\n",
    "# train_losses = train(model, optimiser, train_set, train_cfg)\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 - Train Loss: 0.0669 - LR: 0.0003 - WD: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 - Train Loss: 0.0445 - LR: 0.0003 - WD: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     14\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m get_optimiser(model, opt_cfg)\n\u001b[0;32m     15\u001b[0m train_cfg \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddp_rank\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     30\u001b[0m }\n\u001b[1;32m---> 31\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses)\n\u001b[0;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\hepa\\Utils\\train_min.py:110\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimiser, train_dataset, cfg)\u001b[0m\n\u001b[0;32m     98\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(\n\u001b[0;32m     99\u001b[0m     img1\u001b[38;5;241m=\u001b[39mimages1, \n\u001b[0;32m    100\u001b[0m     img2\u001b[38;5;241m=\u001b[39mimages2, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# targets, action = augment(images1, 0.25)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m#     preds = model.predict(images1, action)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m#     loss = F.mse_loss(preds, targets)\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# epoch_train_norms[i] = torch.norm(torch.stack([torch.norm(p.grad) for p in model.parameters() if p.grad is not None]), 2).detach()\u001b[39;00m\n\u001b[0;32m    114\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Methods.HEPA.train_basic import train as train_hepa_basic\n",
    "from Models import iGPA\n",
    "from Utils.utils import get_optimiser\n",
    "from Utils.train_min import train\n",
    "\n",
    "model = iGPA(1, 5).to(device)\n",
    "opt_cfg = {\n",
    "    'optimiser': 'AdamW',\n",
    "    'exclude_bias': True,\n",
    "    'exclude_bn': True,\n",
    "    'betas': (0.9, 0.999),\n",
    "    'momentum': 0.9,\n",
    "}\n",
    "optimiser = get_optimiser(model, opt_cfg)\n",
    "train_cfg = {\n",
    "    'device': 'cuda',\n",
    "    'ddp_rank': 0,\n",
    "    'warmup': 10,\n",
    "    'flat': 0,\n",
    "    'num_epochs': 250,\n",
    "    'batch_size': 256,\n",
    "    'start_lr': 3e-4,\n",
    "    'end_lr': 1e-6,\n",
    "    'start_wd': 0.04,\n",
    "    'end_wd': 0.4,\n",
    "    'decay_lr': True,\n",
    "    'master_process': True,\n",
    "    'local': True,\n",
    "    'dataset': 'mnist',\n",
    "}\n",
    "train_losses = train(model, optimiser, train_set, train_cfg)\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeag\\Documents\\hepa_old\\Methods\\BYOL\\train.py:58: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6530999541282654\n",
      "Best validation accuracy: 0.6559000015258789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8935999274253845\n",
      "Best validation accuracy: 0.8847001194953918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9608999490737915\n",
      "Best validation accuracy: 0.955000102519989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9756999015808105\n",
      "Best validation accuracy: 0.97760009765625\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "        'name': 'BYOL'\n",
    "    },\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = BYOL\n",
    "    backbone = 'mnist_cnn'\n",
    "    experiment_name = cfg['name']\n",
    "    # experiment = 'mnist_byol'\n",
    "    experiment= 'compare'\n",
    "    log_dir = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    # log_dir = None\n",
    "    save_dir = None\n",
    "    if Model == VAE:\n",
    "        model = Model(1, 256).to(device)\n",
    "    elif Model == AE or Model == BYOL:\n",
    "        model = Model(1).to(device)\n",
    "    else:\n",
    "        model = Model(1, 5).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        lr=3e-5, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True,\n",
    "        exclude_bn=True,\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "        \n",
    "        if isinstance(model, HEPA):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train_hepa(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                stop_at=0,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                loss_fn='mse',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=cfg['beta'],\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                loss_fn='mse',\n",
    "                beta=None,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, Supervised):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train_supervised(\n",
    "                model,\n",
    "                optimiser,\n",
    "                num_epochs=250,\n",
    "                batch_size=cfg['batch_size'],\n",
    "                subset_size=cfg['subset_size'],\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        \n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "        # Evaluate inter-neuron correlations\n",
    "        rep_metrics = eval_representations(model, flatten=False)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('Encoder/test_feature_corr', rep_metrics['corr'])\n",
    "            writer.add_scalar('Encoder/test_feature_std', rep_metrics['std'])\n",
    "\n",
    "    # Evaluate downstream classification accuracy\n",
    "    # for n in [cfg['subset_size']]:\n",
    "    for n in [1, 10, 100, 1000]:\n",
    "    # for n in [100]:\n",
    "        # try:\n",
    "        #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "        #     shutil.copytree(log_dir, dest)\n",
    "        # except:\n",
    "        #     pass\n",
    "        dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "        # dest = log_dir\n",
    "        if log_dir is not None:\n",
    "            writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "        mnist_linear_eval(model, n, writer, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0002932754869107157\n",
       "    maximize: False\n",
       "    weight_decay: 0.05525657534599304\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0002932754869107157\n",
       "    maximize: False\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6703999042510986\n",
      "Best validation accuracy: 0.6752001047134399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8902999758720398\n",
      "Best validation accuracy: 0.884100079536438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.968299925327301\n",
      "Best validation accuracy: 0.9690000414848328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9814999103546143\n",
      "Best validation accuracy: 0.9837000966072083\n"
     ]
    }
   ],
   "source": [
    "# Evaluate downstream classification accuracy\n",
    "# for n in [cfg['subset_size']]:\n",
    "for n in [1, 10, 100, 1000]:\n",
    "# for n in [100]:\n",
    "    # try:\n",
    "    #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    #     shutil.copytree(log_dir, dest)\n",
    "    # except:\n",
    "    #     pass\n",
    "    dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    # dest = log_dir\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, writer, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \r"
     ]
    }
   ],
   "source": [
    "def train_1kmnist(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "):\n",
    "    model.eval()\n",
    "    classifier = nn.Linear(model.num_features, 10, bias=False).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.AdamW(classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        classifier.train()\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        train_loss = 0\n",
    "        for _, (x, label) in loop:\n",
    "            if epoch > 0:\n",
    "                loop.set_description(f'Epoch [{epoch}/{n_epochs}]')\n",
    "                loop.set_postfix(train_loss=train_losses[-1], val_loss=val_losses[-1], val_acc=val_accs[-1])\n",
    "\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                with torch.no_grad():\n",
    "                    x = model.encoder(x)\n",
    "                pred = classifier(x.detach())\n",
    "                loss = criterion(pred, label)\n",
    "\n",
    "            optimiser.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        classifier.eval()\n",
    "        val_loss = 0\n",
    "        num_correct = 0\n",
    "        for x, label in val_loader:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                x = model.encoder(x)\n",
    "                pred = classifier(x)\n",
    "                loss = criterion(pred, label)\n",
    "            val_loss += loss.item()\n",
    "            num_correct += (pred.argmax(1) == label).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accs.append(num_correct / len(val_set) * 100)\n",
    "        \n",
    "    return train_losses, val_losses, val_accs\n",
    "c_t_losses, c_v_losses, c_v_accs = train_1kmnist(model, train_set, val_set, 100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8975999355316162\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_scalar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     writer \u001b[38;5;241m=\u001b[39m SummaryWriter(dest \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier/run_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmnist_linear_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\hepa\\Examples\\MNIST\\mnist_linear_1k.py:148\u001b[0m, in \u001b[0;36mmnist_linear_eval\u001b[1;34m(model, n_per_class, writer, flatten, test)\u001b[0m\n\u001b[0;32m    146\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test_accs\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 148\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassifier/test_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_acc\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_scalar'"
     ]
    }
   ],
   "source": [
    "for n in [100, 1000]:\n",
    "# for n in [100]:\n",
    "    # try:\n",
    "    #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    #     shutil.copytree(log_dir, dest)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    # dest = log_dir\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, None, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "        'name': 'proj-3e-5-mse',\n",
    "    },\n",
    "    {\n",
    "        'name': 'proj-3e-5-mse',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = LAugPC\n",
    "    # backbone = 'mnist_cnn'\n",
    "    backbone='mnist_cnn'\n",
    "    experiment_name = cfg['name']\n",
    "    # experiment = 'pc_vs_ae1'\n",
    "    experiment = 'mnist_linear_'\n",
    "    log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    save_dir = None\n",
    "    model = Model(1, 5,\n",
    "                backbone=backbone, \n",
    "                ).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        # lr = cfg['lr'],\n",
    "        lr=3e-5, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True,\n",
    "        exclude_bn=True,\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "\n",
    "        if isinstance(model, LAugPC):\n",
    "            train_laugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "\n",
    "        if isinstance(model, AugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, SSMAugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.75,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DINO):\n",
    "            train_dino(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                scale_temps=2.0,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # collect 100 of each target index from train_set.targets\n",
    "    writer = SummaryWriter(log_dir + f'classifier/run_{run_no}')\n",
    "    mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = LAugPC\n",
    "    # backbone = 'mnist_cnn'\n",
    "    backbone='mnist_cnn'\n",
    "    experiment_name = 'LAugPC'\n",
    "    experiment = 'pc_vs_ae1'\n",
    "    log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    save_dir = None\n",
    "    model = Model(1, 5,\n",
    "                backbone=backbone, \n",
    "                ).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        # lr = cfg['lr'],\n",
    "        lr=3e-4, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True, \n",
    "        exclude_bn=True\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "\n",
    "        if isinstance(model, LAugPC):\n",
    "            train_laugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "\n",
    "        if isinstance(model, AugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, SSMAugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DAugPC):\n",
    "            train_daugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.75,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DINO):\n",
    "            train_dino(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                scale_temps=2.0,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # collect 100 of each target index from train_set.targets\n",
    "    writer = SummaryWriter(log_dir + f'classifier/run_{run_no}')\n",
    "    mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = HEPA\n",
    "# backbone = 'mnist_cnn'\n",
    "backbone='mnist_cnn'\n",
    "# experiment_name = f'{Model.__name__}-{backbone}'\n",
    "experiment_name = f'HEPA-0'\n",
    "# experiment = 'pc_vs_ae'\n",
    "experiment = 'final'\n",
    "# log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "log_dir = None\n",
    "# save_dir = None\n",
    "model = Model(1, 5, backbone=backbone).to(device)\n",
    "# model = Model(1, backbone).to(device)\n",
    "# model = Model(1, backbone=backbone).to(device)\n",
    "\n",
    "optimiser = get_optimiser(\n",
    "    model, \n",
    "    'AdamW', \n",
    "    lr=3e-4, \n",
    "    wd=0.004, \n",
    "    exclude_bias=True, \n",
    "    exclude_bn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = True\n",
    "if save_dir is not None:\n",
    "    try:\n",
    "        sd = torch.load(save_dir)\n",
    "        # change keys \"project\" to \"transition\"\n",
    "        for key in list(sd.keys()):\n",
    "            if 'project' in key:\n",
    "                sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "        model.load_state_dict(sd)\n",
    "        to_train = False\n",
    "        print('Model loaded successfully')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        print('Model not found, training new model')\n",
    "if to_train:\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(log_dir)\n",
    "    if isinstance(model, HEPA):\n",
    "        train_set.transform = transforms.Compose([\n",
    "        ])\n",
    "        train_hepa(\n",
    "            model,\n",
    "            optimiser,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            num_epochs=250,\n",
    "            batch_size=256,\n",
    "            stop_at=0,\n",
    "            train_aug_scaler='none',\n",
    "            val_aug_scaler='none',\n",
    "            learn_on_ss=False,\n",
    "            writer=writer,\n",
    "            save_dir=save_dir,\n",
    "            save_every=5,\n",
    "        )\n",
    "\n",
    "    if isinstance(model, BYOL):\n",
    "        train_byol(\n",
    "            model,\n",
    "            optimiser,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            num_epochs=500,\n",
    "            batch_size=256,\n",
    "            augmentation=augmentation,\n",
    "            beta=None,\n",
    "            tau_0=0.996,\n",
    "            tau_e=0.999,\n",
    "            tau_T=100,\n",
    "            normalise=True,\n",
    "            learn_on_ss=False,\n",
    "            writer=writer,\n",
    "            save_dir=save_dir,\n",
    "            save_every=5,\n",
    "        )\n",
    "    # if isinstance(model, DINO):\n",
    "    #     train_dino(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=250,\n",
    "    #         batch_size=256,\n",
    "    #         augmentation=augmentation,\n",
    "    #         scale_temps=2.0,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    # if isinstance(model, SimSiam):\n",
    "    #     train_simsiam(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=256,\n",
    "    #         augmentation=augmentation,\n",
    "    #         beta=None,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    # if isinstance(model, SimCLR):\n",
    "    #     train_simclr(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=256,\n",
    "    #         temperature=1.0,\n",
    "    #         augmentation=augmentation,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "    \n",
    "    # if isinstance(model, VAE):\n",
    "    #     train_vae(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=32,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    print(f'Finished training')\n",
    "    if save_dir is not None:\n",
    "        print('Run cell again to load best (val_acc) model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 100 of each target index from train_set.targets\n",
    "writer = SummaryWriter(log_dir)\n",
    "mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_before = train_set[0][0].unsqueeze(0)\n",
    "img_after = F_v2.affine(img, angle=0, translate=(0, 0), scale=1.0, shear=0)\n",
    "\n",
    "# Show example images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "axes[0].imshow(img_before.squeeze().cpu(), cmap='gray')\n",
    "axes[0].set_title(f\"Before\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(img_after.squeeze().cpu(), cmap='gray')\n",
    "axes[1].set_title(f\"After\")\n",
    "axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_set[4][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "def compare(model, img, angle, translate_x, translate_y, scale, shear):\n",
    "    img_aug = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "    # img_pred = model.predict(img, action)\n",
    "    img_pred = model.predict(img.flatten(1), action).view(img.shape)\n",
    "    loss = F.mse_loss(img_aug, img_pred)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axes[0].imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_aug.squeeze().cpu(), cmap='gray')\n",
    "    axes[1].set_title('Augmented')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(img_pred.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    return loss.item()\n",
    "\n",
    "interact(compare, model=fixed(model), img=fixed(img), angle=(-180, 180), translate_x=(-8, 8), translate_y=(-8, 8), scale=(0.75, 1.25), shear=(-25, 25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 1 img of each digit\n",
    "images = []\n",
    "for i in range(10):\n",
    "    while len(images) < i+1:\n",
    "        idx = torch.randint(0, len(test_set), (1,)).item()\n",
    "        if test_set.targets[idx] == i:\n",
    "            images.append(train_set[idx][0].unsqueeze(0))\n",
    "\n",
    "angles = torch.arange(-180, 180, 45).tolist()\n",
    "translate = (0,0)\n",
    "scale = 1.0\n",
    "shear = 0.0\n",
    "\n",
    "truth = {}\n",
    "pred = {}\n",
    "\n",
    "for i in range(10):\n",
    "    images_aug = []\n",
    "    img_preds = []\n",
    "    for angle in angles:\n",
    "        img_aug = F_v2.affine(images[i], angle=angle, translate=translate, scale=scale, shear=shear)\n",
    "        action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "        images_aug.append(img_aug)\n",
    "        img_preds.append(model.predict(images[i], action).view(images[i].shape))\n",
    "    \n",
    "    truth[i] = images_aug\n",
    "    pred[i] = img_preds\n",
    "\n",
    "# Show example images\n",
    "fig, axes = plt.subplots(10, 8, figsize=(10,15))\n",
    "for i in range(10):\n",
    "    for j in range(8):\n",
    "        # axes[2*i, j].imshow(truth[i][j].squeeze().cpu(), cmap='gray')\n",
    "        # axes[2*i, j].axis('off')\n",
    "        # axes[2*i+1, j].imshow(pred[i][j].squeeze().cpu().detach()\n",
    "                            #   , cmap='gray')\n",
    "        # axes[2*i+1, j].axis('off')\n",
    "        axes[i, j].imshow(pred[i][j].squeeze().cpu().detach(), cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Examples.MNIST.mnist_linear_1k import get_mnist_subset_loaders\n",
    "train_loader, _ = get_mnist_subset_loaders(1, 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.functional import augment\n",
    "images , _ = next(iter(train_loader))\n",
    "images_aug, actions = [], []\n",
    "for image in images:\n",
    "    img_aug, action = augment(image, 0.25)\n",
    "    images_aug.append(img_aug)\n",
    "    actions.append(action)\n",
    "\n",
    "images_aug = torch.stack(images_aug)\n",
    "actions = torch.cat(actions, dim=0)\n",
    "images_aug.shape, actions.shape\n",
    "images_pred = model.predict(images, actions, 0)\n",
    "\n",
    "# visualise the images\n",
    "fig, axes = plt.subplots(5, 3, figsize=(3,5))\n",
    "for i in range(5):\n",
    "    axes[i, 0].imshow(images[i].squeeze().cpu(), cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(images_aug[i].squeeze().cpu(), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(images_pred[i].squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "    # label 1st col as original, 2nd as augmented, 3rd as predicted\n",
    "axes[0, 0].set_title('Original', fontsize=10)\n",
    "axes[0, 1].set_title('Augmented', fontsize=10)\n",
    "axes[0, 2].set_title('Predicted', fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
